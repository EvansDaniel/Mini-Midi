# Mini-Midi and The 2nd Order Composer 

Abstract<br><br>

The goal of our project was to create a solar system (implemented with Processing and Pure Data) that reacted to a playing music file in interesting ways. We created the solar system in 3D. The sound file that the solar system is currently "Open Gangnam Style" and the stars of the solar system change colors based on the amplitude (sent to Processing by Pure Data) of the notes played. However, we implemented a 2nd order Markov Chain (the reason for the second order composer title) that can learn based on a <italic>corpus</italic> of midi files that is presented to it. If we had had time to properly integrate it, we would have used the generated music as the music to which the solar system reacted. We will probably implement this soon though. Furthermore, using the OSCp5 library to connect Processing and Pure Data, we implemented a drum mini-MIDI sampler. Processing sent signals to Pure Data about which drum sample to play and, naturally, Pure Data was responsible for playing the sample. Blaise was responsible for most of the graphics and all of the pure data implementation, and I was responsible for creating the 2nd Order Composer. 


<strong>Implementation Details on the Solar System and Pure Data</strong><br><br>

<strong>Implementation Details on the 2nd Order Composer</strong><br><br>

At the beginning of the program, the program will ask the user to provide a few midi files to base its generated music off of. The markov chain will use the corpus to predict the next best note to be played based on the previous two notes (the reason it is referred to as <italic>2nd order</italic> markov chain). Generally speaking, lower order chains produce more randomized sound output because there is less information to predict the next note. Higher order chains produce sound that is more phrasal, but as the order of the chain grows the transitional probability matrix, which is used to determine the next note based on the current two-note sequence in the generated music, becomes more sparse and the probability of any one note being predicted goes down overall. This is because the order of the chain represents how many notes in sequence are used to predict the next one. Thus, the chances of a 5-note sequence coming up many times in a training sequence is low. Because of this, we went with a 2nd order markov chain (although I wanted to try out a 3rd order). I implemented the Markov Chain as a graph. Each vertex in the graph is mapped to a special key denoting a unique sequence of two notes. The edges essentially represent notes that were played in the corpus after the said two-note sequence. Based on that key, the program retrieves the edges of the mapped vertex and determines the one that would best fit after the current two-note sequence generated by the algorithm. 

